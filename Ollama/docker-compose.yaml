version: '2.4'

services:
  ollama:
    image: ollama/ollama:0.5.4
    container_name: llm-server
    mem_limit: 8G
    cpus: 5
    restart: unless-stopped
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    environment:
      - OLLAMA_HOST=0.0.0.0
      - OLLAMA_NUM_THREAD=5
      - OLLAMA_MAX_LOADED_MODELS=1
      - OLLAMA_NUM_PARALLEL=1
      - OLLAMA_NUM_CTX=512
      - OLLAMA_NUM_PREDICT=128
      - OLLAMA_KEEP_ALIVE=10m
    networks:
      - llm-network
volumes:
  ollama_data:
